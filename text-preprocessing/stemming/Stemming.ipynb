{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming**\n"
      ],
      "metadata": {
        "id": "irNZGRiLF-hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Porter Stemmer**"
      ],
      "metadata": {
        "id": "wos0V1GdGxa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mhz73DVJF49B"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "def stem_words(text):\n",
        "  return \" \".join([ps.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "Q8m-L5cEGLa6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ' walk walks walking walked'\n",
        "stem_words(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r1K2TCNuGZ7l",
        "outputId": "8024d961-a845-431c-f592-84384845b8d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'walk walk walk walk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'The Porter Stemmer is one of the most popular stemming algorithms in NLP, developed by Martin Porter in 1980. It reduces words to their root form by applying a series of rules. For example, words like “playing”, “played”, and “plays” are all reduced to “play”. Unlike lemmatization, stemming doesn’t always return a valid word; instead, it cuts off prefixes or suffixes based on heuristics. Porter Stemmer is widely used because it is simple, fast, and effective for many English text preprocessing tasks.'\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpVsR5sGGfg5",
        "outputId": "f2e44c43-0994-4ce3-e55d-7fd7d95e8d05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Porter Stemmer is one of the most popular stemming algorithms in NLP, developed by Martin Porter in 1980. It reduces words to their root form by applying a series of rules. For example, words like “playing”, “played”, and “plays” are all reduced to “play”. Unlike lemmatization, stemming doesn’t always return a valid word; instead, it cuts off prefixes or suffixes based on heuristics. Porter Stemmer is widely used because it is simple, fast, and effective for many English text preprocessing tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "xYTNyy4vHH7p",
        "outputId": "a8cc7412-22d6-4b71-d93e-28f959c58365"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the porter stemmer is one of the most popular stem algorithm in nlp, develop by martin porter in 1980. it reduc word to their root form by appli a seri of rules. for example, word like “playing”, “played”, and “plays” are all reduc to “play”. unlik lemmatization, stem doesn’t alway return a valid word; instead, it cut off prefix or suffix base on heuristics. porter stemmer is wide use becaus it is simple, fast, and effect for mani english text preprocess tasks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Snowball Stemmer**\n",
        "* improved, supports multiple languages"
      ],
      "metadata": {
        "id": "nmY83p_KH1f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# English stemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "words = [\"playing\", \"played\", \"plays\", \"studies\", \"studying\", \"better\"]\n",
        "\n",
        "for word in words:\n",
        "  print(word, \"->\" , stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEuwuv0dHZJI",
        "outputId": "3fddd129-2116-45de-ea6f-3357a844e4a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing -> play\n",
            "played -> play\n",
            "plays -> play\n",
            "studies -> studi\n",
            "studying -> studi\n",
            "better -> better\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Lancaster Stemmer**"
      ],
      "metadata": {
        "id": "GnE2DaQEG9uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "words = [\"playing\", \"played\", \"plays\", \"studies\", \"studying\", \"better\"]\n",
        "\n",
        "for word in words:\n",
        "  print(word , \"->\" , stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKwKJ8gVIUr5",
        "outputId": "0435c8a6-d9d2-4a5e-f43e-ac681fcc478d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing -> play\n",
            "played -> play\n",
            "plays -> play\n",
            "studies -> study\n",
            "studying -> study\n",
            "better -> bet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* too aggressive stemming"
      ],
      "metadata": {
        "id": "byWpb80DHUZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Stemming a Sentence**"
      ],
      "metadata": {
        "id": "WQCpQk0jHfDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "sentence = \"The players are playing football and studying hard for exams\"\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "stems = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "print(\"Original:\" , tokens)\n",
        "print(\"Stemmed:\" , stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbkEW0xtHQ0W",
        "outputId": "f631e3c8-4c21-4ec2-f31d-8b76a04c55ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: ['The', 'players', 'are', 'playing', 'football', 'and', 'studying', 'hard', 'for', 'exams']\n",
            "Stemmed: ['the', 'player', 'are', 'play', 'footbal', 'and', 'studi', 'hard', 'for', 'exam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xG0K3B9CIAFk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}