{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lemmatization**\n"
      ],
      "metadata": {
        "id": "c0mv9m0OS_gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. WordNet Lemmatizer with pos tagging**"
      ],
      "metadata": {
        "id": "RTzmnE5NWACQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X96OoU00S-vQ",
        "outputId": "8ac07c9a-1069-45d2-eee7-c4ea40c4a323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word                Lemma               \n",
            "He                  He                  \n",
            "was                 be                  \n",
            "running             run                 \n",
            "and                 and                 \n",
            "eating              eat                 \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 have                \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swim                \n",
            "after               after               \n",
            "playing             play                \n",
            "long                long                \n",
            "hours               hours               \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "sun                 sun                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wordnet = WordNetLemmatizer()\n",
        "\n",
        "text = ' He was running and eating at the same time. He has bad habit of swimming after playing long hours in the sun.'\n",
        "\n",
        "punctuations= \"?:!,.;\"\n",
        "\n",
        "text_tokens = nltk.word_tokenize(text)\n",
        "\n",
        "for word in text_tokens:\n",
        "  if word in punctuations:\n",
        "    text_tokens.remove(word)\n",
        "\n",
        "text_tokens\n",
        "\n",
        "print(\"{0:20}{1:20}\".format(\"word\" , \"Lemma\"))\n",
        "for word in text_tokens:\n",
        "  print(\"{0:20}{1:20}\".format(word , wordnet.lemmatize(word, pos='v')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* we have to providethe pos in lemmatization"
      ],
      "metadata": {
        "id": "ysQPNFjGUv8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. spaCy Lemmatizer**"
      ],
      "metadata": {
        "id": "4ydjeNVMWYwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.text , \"->\" , token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NIGzOOaUU5U",
        "outputId": "8f787fd9-8b48-4482-9186-8369fc142c11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple -> Apple\n",
            "is -> be\n",
            "looking -> look\n",
            "at -> at\n",
            "buying -> buy\n",
            "U.K. -> U.K.\n",
            "startup -> startup\n",
            "for -> for\n",
            "$ -> $\n",
            "1 -> 1\n",
            "billion -> billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdZ_8vPGWroU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}